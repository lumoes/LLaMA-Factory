#!/bin/bash

# ================= é…ç½®åŒº =================
# æ¿€æ´»ç¯å¢ƒ
source /root/miniconda3/etc/profile.d/conda.sh
conda activate v1  # ä½ çš„ç¯å¢ƒå

# åŸºç¡€æ¨¡å‹è·¯å¾„
MODEL_PATH="/root/autodl-tmp/models/llama3-8b"

# ç»“æœä¿å­˜æ ¹ç›®å½•
BASE_OUTPUT_DIR="saves/llama3-8b/layer_scan"

# æ‰«æçš„å±‚å·åˆ—è¡¨ (æ­¥é•¿ä¸º 4ï¼ŒåŠ ä¸Šæœ€åä¸€å±‚ 31)
# å¯¹åº”: 0, 4, 8,10, 12, 16, 20, 24, 28, 31
LAYERS_TO_SCAN=( 0 4 8 10 12 16 20 24 28 31)

# ç»Ÿä¸€å‚æ•°
LR="1e-4"           # å‡è®¾è¿™æ˜¯ä½ æµ‹å‡ºçš„æœ€ä½³ LR
RANK="256"          # High-Rank æ¨¡æ‹ŸçŸ¥è¯†æ³¨å…¥
STEPS="200"         # å¿«é€Ÿæ‰«æï¼Œ200æ­¥çœ‹ Loss è¶³å¤Ÿäº†
# =========================================

echo "ğŸš€ Starting Layer Sensitivity Scan..."
echo "Layers to scan: ${LAYERS_TO_SCAN[@]}"

for LAYER_ID in "${LAYERS_TO_SCAN[@]}"; do
    echo "----------------------------------------------------"
    echo "ğŸ§ª Processing Layer: $LAYER_ID"
    echo "----------------------------------------------------"

    # [å…³é”®æŠ€æœ¯] åŠ¨æ€æ„å»º lora_target å­—ç¬¦ä¸²
    # LLaMA-Factory æ”¯æŒåç¼€åŒ¹é…ï¼Œè¿™é‡Œæˆ‘ä»¬æ„é€ å”¯ä¸€çš„åç¼€æ¥é”å®šè¯¥å±‚
    # Llama-3 ç»“æ„: model.layers.16.mlp.gate_proj
    TARGET="layers.${LAYER_ID}.mlp.gate_proj,layers.${LAYER_ID}.mlp.up_proj,layers.${LAYER_ID}.mlp.down_proj"
    
    OUTPUT_DIR="${BASE_OUTPUT_DIR}/layer_${LAYER_ID}"

    # å¯åŠ¨è®­ç»ƒ
    # æ³¨æ„ï¼šæˆ‘ä»¬å…³é—­äº† do_eval ä»¥èŠ‚çœæ—¶é—´ï¼Œç›´æ¥çœ‹ training loss æˆ–è€…æœ€åè·‘ä¸€æ¬¡ eval
    # å¦‚æœä½ æƒ³çœ‹ eval lossï¼ŒæŠŠ --do_eval true åŠ ä¸Šï¼Œå¹¶è®¾ç½® val_size
    CUDA_VISIBLE_DEVICES=0 llamafactory-cli train \
        --stage sft \
        --do_train \
        --model_name_or_path $MODEL_PATH \
        --template llama3 \
        --dataset math \
        --finetuning_type lora \
        --lora_rank $RANK \
        --lora_alpha 512 \
        --lora_target "$TARGET" \
        --output_dir $OUTPUT_DIR \
        --overwrite_output_dir \
        --per_device_train_batch_size 8 \
        --gradient_accumulation_steps 4 \
        --learning_rate $LR \
        --lr_scheduler_type cosine \
        --warmup_ratio 0.1 \
        --max_steps $STEPS \
        --logging_steps 10 \
        --save_steps $STEPS \
        --save_total_limit 1 \
        --gradient_checkpointing true \
        --bf16 \
        --trust_remote_code true

    echo "âœ… Layer $LAYER_ID finished. Saved to $OUTPUT_DIR"
done

echo "ğŸ‰ All Scans Completed!"